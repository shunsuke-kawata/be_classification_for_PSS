"""
ChromaDBã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã™ã‚‹ãŸã‚ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä½¿ç”¨ä¾‹:
    python chromadb_data_extractor.py --collection sentence_name_embeddings --limit 10
    python chromadb_data_extractor.py --collection image_embeddings --limit 5 --output vectors.json
"""

import sys
import json
import argparse
from typing import Optional, Dict, Any, List
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent))

from clustering.chroma_db_manager import ChromaDBManager


class ChromaDBDataExtractor:
    """ChromaDBã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, collection_name: str):
        """
        Args:
            collection_name: ChromaDBã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å
        """
        self.collection_name = collection_name
        self.db_manager = ChromaDBManager(collection_name)
        
    def extract_vectors(self, limit: int = 10) -> Dict[str, Any]:
        """
        æŒ‡å®šã•ã‚ŒãŸæ•°ã®ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        
        Args:
            limit: å–å¾—ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã®æœ€å¤§æ•°
            
        Returns:
            dict: {
                'collection_name': str,
                'count': int,
                'data': [
                    {
                        'id': str,
                        'embedding': list,
                        'metadata': dict,
                        'document': str
                    }
                ]
            }
        """
        print(f"ğŸ“Š ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '{self.collection_name}' ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
        
        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å…¨ä½“ã‚’å–å¾—
        try:
            collection = self.db_manager.collection
            
            # limitã‚’æŒ‡å®šã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            results = collection.get(
                limit=limit,
                include=['embeddings', 'metadatas', 'documents']
            )
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’æ•´å½¢
            extracted_data = {
                'collection_name': self.collection_name,
                'count': len(results['ids']),
                'data': []
            }
            
            for i in range(len(results['ids'])):
                item = {
                    'id': results['ids'][i],
                    'embedding': results['embeddings'][i] if results['embeddings'] else None,
                    'metadata': results['metadatas'][i] if results['metadatas'] else {},
                    'document': results['documents'][i] if results['documents'] else None
                }
                extracted_data['data'].append(item)
            
            print(f"âœ… {extracted_data['count']} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸ")
            return extracted_data
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            return {
                'collection_name': self.collection_name,
                'count': 0,
                'data': [],
                'error': str(e)
            }
    
    def print_vectors(self, limit: int = 10, show_full_vector: bool = False):
        """
        ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«å‡ºåŠ›
        
        Args:
            limit: å–å¾—ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã®æœ€å¤§æ•°
            show_full_vector: True ã®å ´åˆã€ãƒ™ã‚¯ãƒˆãƒ«å…¨ä½“ã‚’è¡¨ç¤ºã€‚False ã®å ´åˆã€æœ€åˆã®5æ¬¡å…ƒã®ã¿è¡¨ç¤º
        """
        data = self.extract_vectors(limit)
        
        print("\n" + "="*80)
        print(f"ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å: {data['collection_name']}")
        print(f"å–å¾—ä»¶æ•°: {data['count']}")
        print("="*80 + "\n")
        
        for idx, item in enumerate(data['data'], 1):
            print(f"[{idx}] ID: {item['id']}")
            print(f"    ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {item['metadata']}")
            print(f"    ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: {item['document']}")
            
            if item['embedding']:
                vector = item['embedding']
                vector_dim = len(vector)
                
                if show_full_vector:
                    print(f"    ãƒ™ã‚¯ãƒˆãƒ« (æ¬¡å…ƒæ•°: {vector_dim}):")
                    print(f"    {vector}")
                else:
                    print(f"    ãƒ™ã‚¯ãƒˆãƒ« (æ¬¡å…ƒæ•°: {vector_dim}, æœ€åˆã®5æ¬¡å…ƒ):")
                    print(f"    {vector[:5]} ...")
            else:
                print(f"    ãƒ™ã‚¯ãƒˆãƒ«: ãªã—")
            
            print("-" * 80)
    
    def save_to_json(self, limit: int = 10, output_file: str = "chromadb_vectors.json"):
        """
        ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        
        Args:
            limit: å–å¾—ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã®æœ€å¤§æ•°
            output_file: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
        """
        data = self.extract_vectors(limit)
        
        output_path = Path(output_file)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path.absolute()}")
        print(f"   ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {output_path.stat().st_size / 1024:.2f} KB")


def list_collections():
    """åˆ©ç”¨å¯èƒ½ãªã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§ã‚’è¡¨ç¤º"""
    print("\nğŸ“‹ åˆ©ç”¨å¯èƒ½ãªã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³:")
    collections = [
        "sentence_name_embeddings",
        "sentence_usage_embeddings", 
        "sentence_category_embeddings",
        "image_embeddings"
    ]
    
    for i, col in enumerate(collections, 1):
        print(f"  {i}. {col}")
    print()


def main():
    parser = argparse.ArgumentParser(
        description='ChromaDBã‹ã‚‰ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
ä½¿ç”¨ä¾‹:
  # sentence_name_embeddingsã‹ã‚‰10ä»¶å–å¾—
  python chromadb_data_extractor.py --collection sentence_name_embeddings --limit 10
  
  # image_embeddingsã‹ã‚‰5ä»¶å–å¾—ã—ã¦JSONã«ä¿å­˜
  python chromadb_data_extractor.py --collection image_embeddings --limit 5 --output vectors.json
  
  # ãƒ™ã‚¯ãƒˆãƒ«å…¨ä½“ã‚’è¡¨ç¤º
  python chromadb_data_extractor.py --collection sentence_name_embeddings --limit 3 --full
  
  # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§ã‚’è¡¨ç¤º
  python chromadb_data_extractor.py --list
        '''
    )
    
    parser.add_argument(
        '--collection', '-c',
        type=str,
        help='ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å (sentence_name_embeddings, image_embeddings ãªã©)'
    )
    
    parser.add_argument(
        '--limit', '-l',
        type=int,
        default=10,
        help='å–å¾—ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã®æœ€å¤§æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10)'
    )
    
    parser.add_argument(
        '--output', '-o',
        type=str,
        help='JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹å ´åˆã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å'
    )
    
    parser.add_argument(
        '--full', '-f',
        action='store_true',
        help='ãƒ™ã‚¯ãƒˆãƒ«å…¨ä½“ã‚’è¡¨ç¤º (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æœ€åˆã®5æ¬¡å…ƒã®ã¿)'
    )
    
    parser.add_argument(
        '--list',
        action='store_true',
        help='åˆ©ç”¨å¯èƒ½ãªã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§ã‚’è¡¨ç¤º'
    )
    
    args = parser.parse_args()
    
    # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§è¡¨ç¤º
    if args.list:
        list_collections()
        return
    
    # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆ
    if not args.collection:
        print("âŒ ã‚¨ãƒ©ãƒ¼: --collection ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
        print()
        list_collections()
        parser.print_help()
        return
    
    # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
    extractor = ChromaDBDataExtractor(args.collection)
    
    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹å ´åˆ
    if args.output:
        extractor.save_to_json(limit=args.limit, output_file=args.output)
    
    # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«å‡ºåŠ›
    extractor.print_vectors(limit=args.limit, show_full_vector=args.full)


if __name__ == "__main__":
    main()
