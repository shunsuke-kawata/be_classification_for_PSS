"""
å˜èªåˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

æ–‡ç¯€ã‹ã‚‰å˜èªã‚’æŠ½å‡ºã—ã€ä¸Šä½èªã‚’å–å¾—ã—ã¦é¡ä¼¼åº¦ã‚’è¨ˆç®—ã™ã‚‹æ©Ÿèƒ½ã‚’æä¾›
"""

import re
from collections import defaultdict
from typing import Dict, List, Tuple, Set

import spacy
from nltk.corpus import wordnet as wn
import nltk
import numpy as np
from sentence_transformers import SentenceTransformer, util

from config import CAPTION_STOPWORDS


class WordAnalyzer:
    """å˜èªåˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, embedding_model: SentenceTransformer):
        """
        åˆæœŸåŒ–
        
        Args:
            embedding_model: åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«
        """
        self.embedding_model = embedding_model
        self.nlp = None
        self._initialize_nlp()
    
    def _initialize_nlp(self):
        """spacy ã¨ WordNet ã‚’åˆæœŸåŒ–"""
        print(f"    ğŸ“š spacy ã¨ WordNet ã‚’åˆæœŸåŒ–ä¸­...")
        
        # spacy ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
        try:
            self.nlp = spacy.load('en_core_web_md')
            print(f"    âœ… spaCy ãƒ¢ãƒ‡ãƒ« (en_core_web_md) èª­ã¿è¾¼ã¿å®Œäº†")
        except OSError:
            print(f"    âŒ spaCy ãƒ¢ãƒ‡ãƒ« (en_core_web_md) ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            print(f"    ğŸ’¡ ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§æ‰‹å‹•ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„: python -m spacy download en_core_web_md")
            raise
        
        # nltk ã® WordNet ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªï¼ˆDockerãƒ“ãƒ«ãƒ‰æ™‚ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã®ã¯ãšï¼‰
        try:
            nltk.data.find('corpora/wordnet')
            print(f"    âœ… WordNet ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†")
        except LookupError:
            print(f"    ğŸ“¥ WordNet ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
            nltk.download('wordnet', quiet=True)
            nltk.download('omw-1.4', quiet=True)
            print(f"    âœ… WordNet ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†")
        
        print(f"    âœ… spacy ã¨ WordNet ã®åˆæœŸåŒ–å®Œäº†")
    
    def get_common_category(self, word1: str, word2: str) -> Tuple[List[str], float]:
        """
        2ã¤ã®å˜èªã®å…±é€šã‚«ãƒ†ã‚´ãƒªï¼ˆæœ€ã‚‚è¿‘ã„å…±é€šä¸Šä½æ¦‚å¿µï¼‰ã‚’å–å¾—
        
        Args:
            word1: å˜èª1
            word2: å˜èª2
            
        Returns:
            (å…±é€šã‚«ãƒ†ã‚´ãƒªåã®ãƒªã‚¹ãƒˆ, ã‚¹ã‚³ã‚¢)
        """
        synsets1 = wn.synsets(word1)
        synsets2 = wn.synsets(word2)

        if not synsets1 or not synsets2:
            return [], -1
        
        best_pair = None
        best_score = -1

        # å…¨ã¦ã®æ„å‘³ã®çµ„ã¿åˆã‚ã›ã‚’æ¯”è¼ƒ
        for s1 in synsets1:
            for s2 in synsets2:
                # æœ€ã‚‚è¿‘ã„å…±é€šä¸Šä½æ¦‚å¿µã‚’å–å¾—
                common = s1.lowest_common_hypernyms(s2)
                if not common:
                    continue
                
                # "è·é›¢ãŒè¿‘ã„ã»ã©ä¸€èˆ¬ã‚«ãƒ†ã‚´ãƒªã¨ã—ã¦é©åˆ‡" ã¨ã¿ãªã™
                # ï¼ˆsynset ã«å®šç¾©ã•ã‚ŒãŸæ·±ã•ã‚’ä½¿ã†ï¼‰
                score = max([c.min_depth() for c in common])

                if score > best_score:
                    best_score = score
                    best_pair = common

        if best_pair:
            # æœ€ã‚‚ä»£è¡¨çš„ãªã‚«ãƒ†ã‚´ãƒªåã‚’è¿”ã™
            category_names = [c.name().split('.')[0] for c in best_pair]
            return category_names, best_score
        
        return [], -1
    
    @staticmethod
    def extract_words(sentence: str) -> List[str]:
        """
        æ–‡ã‹ã‚‰å˜èªã‚’æŠ½å‡ºï¼ˆ2æ–‡å­—ä»¥ä¸Šã®è‹±å˜èªã®ã¿ã€ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ã‚’é™¤å¤–ï¼‰
        
        Args:
            sentence: æ–‡ç¯€
            
        Returns:
            å˜èªã®ãƒªã‚¹ãƒˆ
        """
        stop_words_lower = [w.lower() for w in CAPTION_STOPWORDS]
        words = re.findall(r'\b[a-zA-Z]{2,}\b', sentence.lower())
        return [w for w in words if w not in stop_words_lower]
    
    def analyze_folder_words(
        self,
        folder_sentences_by_position: Dict[str, Dict[int, List[str]]],
        target_position: int,
        folder_ids: List[str],
        folder_id_to_name: Dict[str, str]
    ) -> Tuple[Dict[str, Dict[str, int]], Dict[str, List[Tuple[str, int]]]]:
        """
        å„ãƒ•ã‚©ãƒ«ãƒ€ã®æ–‡ç¯€ä½ç½®ã‹ã‚‰å˜èªã‚’æŠ½å‡ºã—ã€é »åº¦ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        
        Args:
            folder_sentences_by_position: {folder_id: {position: [sentences]}}
            target_position: å¯¾è±¡ã®æ–‡ç¯€ä½ç½®
            folder_ids: ãƒ•ã‚©ãƒ«ãƒ€IDã®ãƒªã‚¹ãƒˆ
            folder_id_to_name: {folder_id: folder_name}
            
        Returns:
            (folder_word_frequencies, folder_top_words)
            - folder_word_frequencies: {folder_id: {word: count}}
            - folder_top_words: {folder_id: [(word, freq), ...]}
        """
        folder_word_frequencies = {}
        
        for folder_id in folder_ids:
            if target_position not in folder_sentences_by_position[folder_id]:
                continue
            
            # ãã®æ–‡ç¯€ä½ç½®ã®å…¨æ–‡ã‚’å–å¾—
            target_sentences = folder_sentences_by_position[folder_id][target_position]
            
            # å…¨æ–‡ã‹ã‚‰å˜èªã‚’æŠ½å‡ºã—ã¦ã‚«ã‚¦ãƒ³ãƒˆ
            word_count = {}
            for sentence in target_sentences:
                words = self.extract_words(sentence)
                for word in words:
                    word_count[word] = word_count.get(word, 0) + 1
            
            folder_word_frequencies[folder_id] = word_count
            
            # ä½¿ç”¨é »åº¦ã®é«˜ã„é †ã«ãƒ©ãƒ³ã‚¯ä»˜ã‘ï¼ˆãƒˆãƒƒãƒ—10ï¼‰
            top_words = sorted(word_count.items(), key=lambda x: x[1], reverse=True)[:10]
            folder_name = folder_id_to_name[folder_id]
            print(f"      ğŸ“ {folder_name}: {len(word_count)}å€‹ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯å˜èª")
            top_words_str = ', '.join([f"{w}({c})" for w, c in top_words[:5]])
            print(f"         é »å‡ºå˜èªãƒˆãƒƒãƒ—5: {top_words_str}")
        
        return folder_word_frequencies, None
    
    def get_top_unique_words(
        self,
        folder_word_frequencies: Dict[str, Dict[str, int]],
        folder_ids: List[str],
        folder_id_to_name: Dict[str, str],
        top_n: int = 5
    ) -> Dict[str, List[Tuple[str, int]]]:
        """
        å„ãƒ•ã‚©ãƒ«ãƒ€ã®é »å‡ºå˜èªãƒˆãƒƒãƒ—Nã‹ã‚‰å…±é€šå˜èªã‚’é™¤å¤–
        
        Args:
            folder_word_frequencies: {folder_id: {word: count}}
            folder_ids: ãƒ•ã‚©ãƒ«ãƒ€IDã®ãƒªã‚¹ãƒˆ
            folder_id_to_name: {folder_id: folder_name}
            top_n: ä¸Šä½Nä»¶
            
        Returns:
            {folder_id: [(word, freq), ...]}
        """
        # å„ãƒ•ã‚©ãƒ«ãƒ€ã®é »å‡ºå˜èªãƒˆãƒƒãƒ—Nã‚’å–å¾—
        folder_top_words = {}
        for folder_id in folder_ids:
            sorted_words = sorted(
                folder_word_frequencies[folder_id].items(),
                key=lambda x: x[1],
                reverse=True
            )[:top_n]
            folder_top_words[folder_id] = sorted_words
        
        # ãƒˆãƒƒãƒ—NåŒå£«ã‚’æ¯”è¼ƒã—ã¦å…±é€šã™ã‚‹å˜èªã‚’ç‰¹å®š
        top_words_per_folder = [set([w for w, _ in folder_top_words[fid]]) for fid in folder_ids]
        common_words = set.intersection(*top_words_per_folder)
        
        print(f"       ãƒˆãƒƒãƒ—{top_n}å†…ã§å…±é€šã™ã‚‹å˜èªæ•°: {len(common_words)}å€‹")
        if len(common_words) > 0:
            common_words_str = ', '.join(sorted(list(common_words)))
            print(f"       å…±é€šå˜èª: {common_words_str}")
        
        # å„ãƒ•ã‚©ãƒ«ãƒ€ã®é »å‡ºå˜èªãƒˆãƒƒãƒ—Nã‹ã‚‰å…±é€šå˜èªã‚’é™¤å¤–
        folder_top_unique_words = {}
        
        for folder_id in folder_ids:
            unique_top_words = [
                (w, freq) for w, freq in folder_top_words[folder_id]
                if w not in common_words
            ]
            
            folder_top_unique_words[folder_id] = unique_top_words
            
            folder_name = folder_id_to_name[folder_id]
            print(f"       ğŸ“ {folder_name}: {len(unique_top_words)}å€‹ã®å›ºæœ‰å˜èªï¼ˆãƒˆãƒƒãƒ—{top_n}ã‹ã‚‰å…±é€šå˜èªé™¤å¤–å¾Œï¼‰")
            if len(unique_top_words) > 0:
                top_display = ', '.join([f"{w}({freq})" for w, freq in unique_top_words])
                print(f"          å›ºæœ‰å˜èª: {top_display}")
        
        return folder_top_unique_words
    
    def compute_common_category_similarity(
        self,
        folder_top_unique_words: Dict[str, List[Tuple[str, int]]],
        folder_ids: List[str],
        folder_id_to_name: Dict[str, str],
        similarity_threshold: float = 0.5
    ) -> Tuple[List[dict], List[dict]]:
        """
        å…±é€šã‚«ãƒ†ã‚´ãƒªãƒ™ãƒ¼ã‚¹ã®é¡ä¼¼åº¦ãƒãƒƒãƒãƒ³ã‚°
        
        Args:
            folder_top_unique_words: {folder_id: [(word, freq), ...]}
            folder_ids: ãƒ•ã‚©ãƒ«ãƒ€IDã®ãƒªã‚¹ãƒˆ
            folder_id_to_name: {folder_id: folder_name}
            similarity_threshold: é¡ä¼¼åº¦ã®é–¾å€¤
            
        Returns:
            (all_category_pairs, similar_category_pairs)
        """
        print(f"\n    ğŸ” ã‚¹ãƒ†ãƒƒãƒ—6: å…±é€šã‚«ãƒ†ã‚´ãƒªãƒ™ãƒ¼ã‚¹ã®é¡ä¼¼åº¦ãƒãƒƒãƒãƒ³ã‚°...")
        
        # å…¨ã¦ã®å˜èªãƒšã‚¢ã‚’åé›†
        all_words_with_freq = []
        for folder_id in folder_ids:
            if folder_id not in folder_top_unique_words:
                continue
            for word, freq in folder_top_unique_words[folder_id]:
                all_words_with_freq.append({
                    'folder_id': folder_id,
                    'word': word,
                    'freq': freq
                })
        
        if len(all_words_with_freq) < 2:
            print(f"       âš ï¸ æ¯”è¼ƒã™ã‚‹å˜èªãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆ{len(all_words_with_freq)}å€‹ï¼‰")
            return [], []
        
        # ãƒ•ã‚©ãƒ«ãƒ€é–“ã§å…±é€šã‚«ãƒ†ã‚´ãƒªã‚’è¨ˆç®—
        all_category_pairs = []
        skipped_pairs = []  # ã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸãƒšã‚¢ã‚’è¨˜éŒ²
        
        for i, item1 in enumerate(all_words_with_freq):
            for j, item2 in enumerate(all_words_with_freq):
                if i >= j:
                    continue
                
                # ç•°ãªã‚‹ãƒ•ã‚©ãƒ«ãƒ€é–“ã®ã¿æ¯”è¼ƒ
                if item1['folder_id'] == item2['folder_id']:
                    continue
                
                folder1_name = folder_id_to_name[item1['folder_id']]
                folder2_name = folder_id_to_name[item2['folder_id']]
                
                # å…±é€šã‚«ãƒ†ã‚´ãƒªã‚’å–å¾—
                common_categories, category_score = self.get_common_category(
                    item1['word'],
                    item2['word']
                )
                
                if len(common_categories) == 0 or category_score < 0:
                    # ã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸãƒšã‚¢ã‚’è¨˜éŒ²
                    skipped_pairs.append({
                        'word1': item1['word'],
                        'word2': item2['word'],
                        'folder1': folder1_name,
                        'folder2': folder2_name,
                        'freq1': item1['freq'],
                        'freq2': item2['freq']
                    })
                    continue
                
                # å˜èªã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã§é¡ä¼¼åº¦ã‚’è¨ˆç®—
                word1_embedding = self.embedding_model.encode([item1['word']], convert_to_tensor=True)
                word2_embedding = self.embedding_model.encode([item2['word']], convert_to_tensor=True)
                word_similarity = util.cos_sim(word1_embedding, word2_embedding).item()
                
                pair_info = {
                    'word1': item1['word'],
                    'word2': item2['word'],
                    'folder1_id': item1['folder_id'],
                    'folder2_id': item2['folder_id'],
                    'common_categories': common_categories,
                    'category_score': category_score,
                    'word_similarity': word_similarity,
                    'freq1': item1['freq'],
                    'freq2': item2['freq'],
                    'freq_sum': item1['freq'] + item2['freq']
                }
                
                all_category_pairs.append(pair_info)
                
                category_display = ', '.join(common_categories[:3])
                print(f"         ğŸ”„ {folder1_name} '{item1['word']}' â†” {folder2_name} '{item2['word']}'")
                print(f"            å…±é€šã‚«ãƒ†ã‚´ãƒª: {category_display} (ã‚¹ã‚³ã‚¢: {category_score:.2f})")
                print(f"            å˜èªé¡ä¼¼åº¦: {word_similarity:.3f}, é »åº¦: {item1['freq']}, {item2['freq']}")
        
        # ã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸãƒšã‚¢ã‚’ãƒ­ã‚°å‡ºåŠ›
        if len(skipped_pairs) > 0:
            print(f"\n       âš ï¸ å…±é€šã‚«ãƒ†ã‚´ãƒªãŒè¦‹ã¤ã‹ã‚‰ãšã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸãƒšã‚¢: {len(skipped_pairs)}å€‹")
            for skip in skipped_pairs:
                print(f"         âŒ {skip['folder1']} '{skip['word1']}' (é »åº¦:{skip['freq1']}) â†” {skip['folder2']} '{skip['word2']}' (é »åº¦:{skip['freq2']})")
        
        if len(all_category_pairs) == 0:
            print(f"       âš ï¸ å…±é€šã‚«ãƒ†ã‚´ãƒªã‚’æŒã¤ãƒšã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            if len(skipped_pairs) > 0:
                print(f"       ğŸ’¡ ãƒ’ãƒ³ãƒˆ: WordNetã§å…±é€šã‚«ãƒ†ã‚´ãƒªãŒè¦‹ã¤ã‹ã‚‰ãªã„å˜èªãƒšã‚¢ãŒå¤šã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
                print(f"       ğŸ’¡ è§£æ±ºç­–: ã‚ˆã‚Šä¸€èˆ¬çš„ãªå˜èªã‚’ä½¿ç”¨ã™ã‚‹ã‹ã€é¡ä¼¼åº¦é–¾å€¤ã‚’ä¸‹ã’ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
            return [], []
        
        # ã‚«ãƒ†ã‚´ãƒªã‚¹ã‚³ã‚¢ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆã‚¹ã‚³ã‚¢ãŒé«˜ã„ã»ã©è¿‘ã„ã‚«ãƒ†ã‚´ãƒªï¼‰
        # ã¾ãšã€category_scoreãŒæœ€ä½é–¾å€¤ï¼ˆä¾‹: 1ä»¥ä¸Šï¼‰ã®ãƒšã‚¢ã®ã¿ã‚’å¯¾è±¡
        min_category_score = 1
        filtered_pairs = [p for p in all_category_pairs if p['category_score'] >= min_category_score]
        
        print(f"\n       ğŸ“Š å…±é€šã‚«ãƒ†ã‚´ãƒªã®çµ±è¨ˆ:")
        print(f"          å…¨ãƒšã‚¢æ•°: {len(all_category_pairs)}")
        print(f"          ã‚«ãƒ†ã‚´ãƒªã‚¹ã‚³ã‚¢ >= {min_category_score} ã®ãƒšã‚¢æ•°: {len(filtered_pairs)}")
        
        if len(filtered_pairs) == 0:
            print(f"       âš ï¸ æœ‰åŠ¹ãªå…±é€šã‚«ãƒ†ã‚´ãƒªã‚’æŒã¤ãƒšã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return all_category_pairs, []
        
        # ã‚½ãƒ¼ãƒˆå„ªå…ˆé †ä½:
        # 1. ã‚«ãƒ†ã‚´ãƒªã‚¹ã‚³ã‚¢ï¼ˆé«˜ã„ã»ã©è‰¯ã„ï¼‰
        # 2. å˜èªãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼åº¦ï¼ˆé«˜ã„ã»ã©è‰¯ã„ï¼‰
        # 3. é »åº¦åˆè¨ˆï¼ˆé«˜ã„ã»ã©è‰¯ã„ï¼‰
        sorted_pairs = sorted(
            filtered_pairs,
            key=lambda x: (x['category_score'], x['word_similarity'], x['freq_sum']),
            reverse=True
        )
        
        # é¡ä¼¼åº¦é–¾å€¤ã‚‚è€ƒæ…®ï¼ˆå˜èªé¡ä¼¼åº¦ãŒé–¾å€¤ä»¥ä¸Šã®ã‚‚ã®ï¼‰
        similar_category_pairs = [p for p in sorted_pairs if p['word_similarity'] >= similarity_threshold]
        
        print(f"          å˜èªé¡ä¼¼åº¦ >= {similarity_threshold} ã®ãƒšã‚¢æ•°: {len(similar_category_pairs)}")
        
        # é¡ä¼¼åº¦é–¾å€¤ã‚’æº€ãŸã™ãƒšã‚¢ãŒãªã„å ´åˆã¯ã€ä¸Šä½ã®ãƒšã‚¢ã‚’è¿”ã™
        if len(similar_category_pairs) == 0:
            print(f"       â„¹ï¸ é¡ä¼¼åº¦é–¾å€¤ã‚’æº€ãŸã™ãƒšã‚¢ãŒãªã„ãŸã‚ã€ä¸Šä½3ãƒšã‚¢ã‚’æ¡ç”¨")
            similar_category_pairs = sorted_pairs[:min(3, len(sorted_pairs))]
        
        return all_category_pairs, similar_category_pairs
    
    def select_representative_words(
        self,
        similar_category_pairs: List[dict],
        folder_ids: List[str],
        folder_id_to_name: Dict[str, str],
        folder_top_unique_words: Dict[str, List[Tuple[str, int]]]
    ) -> Dict[str, str]:
        """
        å„ãƒ•ã‚©ãƒ«ãƒ€ã®ä»£è¡¨å˜èªã‚’é¸æŠ
        
        Args:
            similar_category_pairs: é¡ä¼¼ã™ã‚‹å…±é€šã‚«ãƒ†ã‚´ãƒªãƒšã‚¢ã®ãƒªã‚¹ãƒˆ
            folder_ids: ãƒ•ã‚©ãƒ«ãƒ€IDã®ãƒªã‚¹ãƒˆ
            folder_id_to_name: {folder_id: folder_name}
            folder_top_unique_words: {folder_id: [(word, freq), ...]}
            
        Returns:
            {folder_id: representative_word}
        """
        if len(similar_category_pairs) == 0:
            return {}
        
        print(f"\n       ğŸ¯ å…±é€šã‚«ãƒ†ã‚´ãƒªã‚’æŒã¤å˜èªãƒšã‚¢:")
        for pair in similar_category_pairs:
            folder1_name = folder_id_to_name[pair['folder1_id']]
            folder2_name = folder_id_to_name[pair['folder2_id']]
            category_display = ', '.join(pair['common_categories'][:3])
            print(f"         '{pair['word1']}' ({folder1_name}, é »åº¦:{pair['freq1']}) â†” '{pair['word2']}' ({folder2_name}, é »åº¦:{pair['freq2']})")
            print(f"           å…±é€šã‚«ãƒ†ã‚´ãƒª: {category_display} (ã‚¹ã‚³ã‚¢: {pair['category_score']:.2f})")
            print(f"           å˜èªé¡ä¼¼åº¦: {pair['word_similarity']:.3f}, é »åº¦åˆè¨ˆ: {pair['freq_sum']}")
        
        # å„ãƒ•ã‚©ãƒ«ãƒ€ã®ä»£è¡¨å˜èªã‚’é¸æŠ
        # å„ªå…ˆé †ä½: ã‚«ãƒ†ã‚´ãƒªã‚¹ã‚³ã‚¢ > å˜èªé¡ä¼¼åº¦ > é »åº¦
        folder_word_candidates = defaultdict(list)
        
        for pair in similar_category_pairs:
            folder_word_candidates[pair['folder1_id']].append(
                (pair['word1'], pair['freq1'], pair['category_score'], pair['word_similarity'])
            )
            folder_word_candidates[pair['folder2_id']].append(
                (pair['word2'], pair['freq2'], pair['category_score'], pair['word_similarity'])
            )
        
        folder_representative_words = {}
        
        for folder_id in folder_ids:
            if folder_id in folder_word_candidates and len(folder_word_candidates[folder_id]) > 0:
                # ã‚«ãƒ†ã‚´ãƒªã‚¹ã‚³ã‚¢ > å˜èªé¡ä¼¼åº¦ > é »åº¦ ã®é †ã§ã‚½ãƒ¼ãƒˆ
                sorted_candidates = sorted(
                    folder_word_candidates[folder_id],
                    key=lambda x: (x[2], x[3], x[1]),  # (category_score, word_similarity, freq)
                    reverse=True
                )
                best_word = sorted_candidates[0][0]
                folder_representative_words[folder_id] = best_word
        
        if len(folder_representative_words) > 0:
            classification_words = list(set(folder_representative_words.values()))
            
            print(f"\n       ğŸ¯ ãƒ•ã‚©ãƒ«ãƒ€åˆ†é¡åŸºæº–ï¼ˆå…±é€šã‚«ãƒ†ã‚´ãƒªãƒ™ãƒ¼ã‚¹ï¼‰: {classification_words}")
            print(f"       å„ãƒ•ã‚©ãƒ«ãƒ€ã®ä»£è¡¨å˜èª:")
            for folder_id, word in folder_representative_words.items():
                folder_name = folder_id_to_name[folder_id]
                freq = dict(folder_top_unique_words[folder_id])[word]
                
                # å…±é€šã‚«ãƒ†ã‚´ãƒªã‚’æ¢ã™
                matching_pairs = [p for p in similar_category_pairs 
                                 if (p['folder1_id'] == folder_id and p['word1'] == word) 
                                 or (p['folder2_id'] == folder_id and p['word2'] == word)]
                
                if matching_pairs:
                    best_match = matching_pairs[0]
                    category_display = ', '.join(best_match['common_categories'][:3])
                    print(f"         ğŸ“ {folder_name}: {word} (ä½¿ç”¨é »åº¦: {freq}å›, å…±é€šã‚«ãƒ†ã‚´ãƒª: {category_display})")
                else:
                    print(f"         ğŸ“ {folder_name}: {word} (ä½¿ç”¨é »åº¦: {freq}å›)")
        
        return folder_representative_words
