import copy
import json
from pathlib import Path
from fastapi import APIRouter, HTTPException, status,Response
import sys
import os

from fastapi.responses import JSONResponse
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../')))
from db_utils.commons import create_connect_session,execute_query
from db_utils.validators import validate_data
from db_utils.models import CustomResponseModel, LoginUser,JoinUser
from config import CLUSTERING_STATUS,DEFAULT_IMAGE_PATH,DEFAULT_OUTPUT_PATH
from clustering.clustering_manager import ChromaDBManager, InitClusteringManager
from clustering.mongo_db_manager import MongoDBManager
from clustering.mongo_db_manager import MongoDBManager
from fastapi import BackgroundTasks, Query
from collections import defaultdict
from typing import List
from clustering.mongo_result_manager import ResultManager

#åˆ†å‰²ã—ãŸã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ä½œæˆ
#ãƒ­ã‚°ã‚¤ãƒ³æ“ä½œ
action_endpoint = APIRouter()

@action_endpoint.get("/action/clustering/result/{mongo_result_id}",tags=["action"],description="åˆæœŸã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœã‚’å–å¾—ã™ã‚‹")
def get_clustering_result(mongo_result_id:str):
    from clustering.mongo_result_manager import ResultManager
    result_manager = ResultManager(mongo_result_id)
    
    # ResultManagerã®get_result()ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨
    result_data = result_manager.get_result()
    
    if result_data:
        return JSONResponse(
            status_code=status.HTTP_200_OK,
            content={"message": "success", "result": result_data}
        )
    else:
        return JSONResponse(
            status_code=status.HTTP_404_NOT_FOUND,
            content={"message": "Clustering result not found"}
        )
        
        

@action_endpoint.get("/action/clustering/init/{project_id}", tags=["action"], description="åˆæœŸã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚’å®Ÿè£…ã™ã‚‹")
def execute_init_clustering(
    project_id: int = None,
    user_id: int = None,
    background_tasks: BackgroundTasks = None
):
    if project_id is None or user_id is None:
        return JSONResponse(
            status_code=status.HTTP_400_BAD_REQUEST,
            content={"message": "project_id and user_id is required", "data": None}
        )

    try:
        project_id = int(project_id)
        user_id = int(user_id)
    except:
        return JSONResponse(
            status_code=status.HTTP_400_BAD_REQUEST,
            content={"message": "project_id or user_id is invalid", "data": None}
        )

    connect_session = create_connect_session()
    query_text = f"""
        SELECT project_memberships.init_clustering_state, project_memberships.mongo_result_id,projects.original_images_folder_path
        FROM project_memberships
        JOIN projects ON project_memberships.project_id = projects.id
        WHERE project_memberships.project_id = {project_id} AND project_memberships.user_id = {user_id};
    """

    result, _ = execute_query(session=connect_session, query_text=query_text)
    result_mappings = result.mappings().first()

    if result_mappings is None:
        return JSONResponse(
            status_code=status.HTTP_404_NOT_FOUND,
            content={"message": "project or membership not found", "data": None}
        )

    init_clustering_state = result_mappings["init_clustering_state"]
    original_images_folder_path = result_mappings["original_images_folder_path"]
    mongo_result_id = result_mappings["mongo_result_id"]

    if init_clustering_state == CLUSTERING_STATUS.EXECUTING or init_clustering_state ==CLUSTERING_STATUS.FINISHED:
        return JSONResponse(
            status_code=status.HTTP_400_BAD_REQUEST,
            content={"message": "init clustering already started", "data": None}
        )

    # å¯¾è±¡ç”»åƒã®å–å¾—
    query_text = f"""
        SELECT clustering_id,chromadb_sentence_id,chromadb_image_id
        FROM images
        WHERE project_id = {project_id} AND is_created_caption = TRUE;
    """

    result, _ = execute_query(session=connect_session, query_text=query_text)
    if result is None:
        return JSONResponse(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            content={"message": "failed to get images", "data": None}
        )

    rows = result.mappings().all()
    # æ¤œç´¢ç”¨è¾æ›¸ã‚’ä½œæˆ
    by_clustering_id = {}
    by_chromadb_sentence_id = {}
    by_chromadb_image_id = {}

    for row in rows:
        cid = row["clustering_id"]
        sid = row["chromadb_sentence_id"]
        iid = row["chromadb_image_id"]
        
        by_clustering_id[cid] = {"sentence_id": sid, "image_id": iid}
        by_chromadb_sentence_id[sid] = {"clustering_id": cid, "image_id": iid}
        by_chromadb_image_id[iid] = {"clustering_id": cid, "sentence_id": sid}
    
    # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†ã«æ¸¡ã™é–¢æ•°
    def run_clustering(cid_dict:dict,sid_dict:dict,iid_dict:dict,project_id:int, original_images_folder_path:str):
        try:
            cl_module = InitClusteringManager(
                sentence_db=ChromaDBManager('sentence_embeddings'),
                image_db=ChromaDBManager("image_embeddings"),
                images_folder_path=f"./{DEFAULT_IMAGE_PATH}/{original_images_folder_path}",
                output_base_path=f"./{DEFAULT_OUTPUT_PATH}/{project_id}",
            )
            
            target_sentence_ids = list(sid_dict.keys())
            target_image_ids = list(iid_dict.keys())
            embeddings = cl_module.sentence_db.get_data_by_ids(target_sentence_ids)['embeddings']
            cluster_num, _ = cl_module.get_optimal_cluster_num(embeddings=embeddings)
            result_dict,all_nodes = cl_module.clustering(
                sentence_db_data=cl_module.sentence_db.get_data_by_ids(target_sentence_ids),
                image_db_data=cl_module.image_db.get_data_by_ids(target_image_ids),
                clustering_id_dict=cid_dict,
                sentence_id_dict=sid_dict,
                image_id_dict=iid_dict,
                cluster_num=cluster_num,
                output_folder=True,
                output_json=True
            )
            
            # all_nodesã‚’é…åˆ—ã‹ã‚‰è¾æ›¸å½¢å¼ã«å¤‰æ›ï¼ˆidã‚’ã‚­ãƒ¼ã¨ã—ã¦ï¼‰
            all_nodes_dict = {}
            for node in all_nodes:
                if 'id' in node:
                    all_nodes_dict[node['id']] = node
            
            from clustering.mongo_result_manager import ResultManager
            result_manager = ResultManager(mongo_result_id)
            result_manager.update_result(result_dict, all_nodes_dict)
        except Exception as e:
            print(f"Error during clustering:{e}")
            
            # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯åˆæœŸåŒ–çŠ¶æ…‹ã‚’æ›´æ–°
            clustering_state = CLUSTERING_STATUS.FAILED
        else:
            clustering_state = CLUSTERING_STATUS.FINISHED
        finally:
            
            # åˆæœŸåŒ–çŠ¶æ…‹ã‚’æ›´æ–°
            update_query = f"""
                UPDATE project_memberships
                SET init_clustering_state = '{clustering_state}'
                WHERE project_id = {project_id} AND user_id = {user_id};
            """
            _, _ = execute_query(session=connect_session, query_text=update_query)
                
    # éåŒæœŸå®Ÿè¡Œ
    print(original_images_folder_path)
    background_tasks.add_task(run_clustering, by_clustering_id, by_chromadb_sentence_id,by_chromadb_image_id,project_id, original_images_folder_path)
    
    # åˆæœŸåŒ–çŠ¶æ…‹ã‚’æ›´æ–°
    update_query = f"""
        UPDATE project_memberships
        SET init_clustering_state = '{CLUSTERING_STATUS.EXECUTING}'
        WHERE project_id = {project_id} AND user_id = {user_id};
    """
    #åˆæœŸåŒ–çŠ¶æ…‹ã‚’æ›´æ–°
    _, _ = execute_query(session=connect_session, query_text=update_query)
    
    return JSONResponse(
        status_code=status.HTTP_200_OK,
        content={"message": "init clustering started in background", "data": project_id}
    )


@action_endpoint.put("/action/clustering/move/{mongo_result_id}", tags=["action"], description="ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœã®ãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ ã‚’å¤‰æ›´ã™ã‚‹")
def move_clustering_items(
    mongo_result_id: str,
    source_type: str = Query(..., description="ç§»å‹•ã™ã‚‹ã‚½ãƒ¼ã‚¹ã®ã‚¿ã‚¤ãƒ—: 'folders' ã¾ãŸã¯ 'images'"),
    sources: List[str] = Query(..., description="ç§»å‹•ã™ã‚‹è¦ç´ ã®åå‰ã®é…åˆ—"),
    destination_folder: str = Query(..., description="ç§»å‹•å…ˆã®ãƒ•ã‚©ãƒ«ãƒ€å")
):
    """
    æŒ‡å®šã—ãŸmongo_result_idã«ç´ã¤ã„ãŸjsonã‚’ç·¨é›†ã—ã¦ãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ ã‚’ä½œã‚Šæ›¿ãˆã¦nosqlãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã‚³ãƒŸãƒƒãƒˆã™ã‚‹
    
    Args:
        mongo_result_id: MongoDBã®çµæœID
        source_type: ç§»å‹•ã™ã‚‹ã‚½ãƒ¼ã‚¹ã®ã‚¿ã‚¤ãƒ— ("folders" ã¾ãŸã¯ "images")
        sources: ç§»å‹•ã™ã‚‹è¦ç´ ã®åå‰ã®é…åˆ—
        destination_folder: ç§»å‹•å…ˆã®ãƒ•ã‚©ãƒ«ãƒ€å
    """
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¤œè¨¼
    if source_type not in ["folders", "images"]:
        return JSONResponse(
            status_code=status.HTTP_400_BAD_REQUEST,
            content={"message": "source_type must be 'folders' or 'images'", "data": None}
        )
    
    if not sources or len(sources) == 0:
        return JSONResponse(
            status_code=status.HTTP_400_BAD_REQUEST,
            content={"message": "sources must not be empty", "data": None}
        )
    
    if not destination_folder:
        return JSONResponse(
            status_code=status.HTTP_400_BAD_REQUEST,
            content={"message": "destination_folder is required", "data": None}
        )

    result_manager = ResultManager(mongo_result_id)
    
    if source_type == "folders":
        try:
            result_manager.move_folder_node(sources, destination_folder)
        except Exception as e:
            return JSONResponse(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                content={"message": f"ãƒ•ã‚©ãƒ«ãƒ€ç§»å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}", "data": None}
            )
            
    elif source_type == "images":
        try:
            for source in sources:
                result_manager.move_file_node(source, destination_folder)
        except Exception as e:
            return JSONResponse(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                content={"message": f"ãƒ•ã‚¡ã‚¤ãƒ«ç§»å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}", "data": None}
            )
            
    else:
        return JSONResponse(
            status_code=status.HTTP_400_BAD_REQUEST,
            content={"message": "source_type must be 'folders' or 'images'", "data": None}
        )
    


    return JSONResponse(
        status_code=status.HTTP_200_OK,
        content={"message": "success", "data": None}
    )
    
    items_to_move = {}
    
    if not items_to_move:
        return JSONResponse(
            status_code=status.HTTP_404_NOT_FOUND,
            content={
                "message": f"No {source_type} found to move", 
                "data": {
                    "searched_ids": sources
                }
            }
        )
        if source_type == "folders":
            print(f"   - ãƒ•ã‚©ãƒ«ãƒ€: {key}")
            print(f"     - is_leaf: {value.get('is_leaf')}")
            print(f"     - parent_id: {value.get('parent_id')}")
            if "data" in value:
                print(f"     - å­è¦ç´ æ•°: {len(value['data'])}")
                print(f"     - å­è¦ç´ : {list(value['data'].keys())}")
        else:
            print(f"   - ç”»åƒ: {key}")
    
    # æŒ¿å…¥å¾Œã®äºˆæƒ³çŠ¶æ…‹ã‚’è¡¨ç¤º
    print(f"ğŸ”® æŒ¿å…¥å¾Œã®äºˆæƒ³çŠ¶æ…‹:")
    new_destination_data = destination_data.copy()
    new_destination_data.update(items_to_move)
    print(f"   - æŒ¿å…¥å¾Œã®è¦ç´ æ•°: {len(new_destination_data)}")
    print(f"   - æŒ¿å…¥å¾Œã®è¦ç´ : {list(new_destination_data.keys())}")
        
    # ç§»å‹•å…ˆã«åŒã˜åå‰ã®è¦ç´ ãŒå­˜åœ¨ã—ãªã„ã‹ãƒã‚§ãƒƒã‚¯
    print(f"ğŸ” ç§»å‹•å…ˆã®åå‰é‡è¤‡ãƒã‚§ãƒƒã‚¯ä¸­...")
    
    if "data" not in destination_node:
        destination_node["data"] = {}
    
    conflicting_items = []
    for key in items_to_move.keys():
        if key in destination_node["data"]:
            conflicting_items.append(key)
    
    if conflicting_items:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: ç§»å‹•å…ˆã«åŒã˜åå‰ã®è¦ç´ ãŒæ—¢ã«å­˜åœ¨ã—ã¾ã™: {conflicting_items}")
        return JSONResponse(
            status_code=status.HTTP_400_BAD_REQUEST,
            content={"message": f"Items with same names already exist in destination: {conflicting_items}", "data": None}
        )
    
    print(f"âœ… åå‰é‡è¤‡ãƒã‚§ãƒƒã‚¯å®Œäº†: é‡è¤‡ãªã—")
    
    # å®Ÿéš›ã®MongoDBãƒ‡ãƒ¼ã‚¿æ›¸ãæ›ãˆå‡¦ç†
    print(f"ğŸ’¾ MongoDBãƒ‡ãƒ¼ã‚¿æ›¸ãæ›ãˆå‡¦ç†é–‹å§‹...")
    
    # ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®å…ƒãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒ
    original_result_structure = copy.deepcopy(result_structure)
    print(f"ğŸ“‹ ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®å…ƒãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒã—ã¾ã—ãŸ")
    
    def rollback_data():
        """ãƒ‡ãƒ¼ã‚¿ã‚’å…ƒã®çŠ¶æ…‹ã«æˆ»ã™"""
        try:
            print(f"ğŸ”„ ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†é–‹å§‹...")
            result_manager._mongo_module.update_document(
                collection_name='clustering_results',
                query={"mongo_result_id": mongo_result_id},
                update={"result": original_result_structure}
            )
            print(f"âœ… ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Œäº†: ãƒ‡ãƒ¼ã‚¿ã‚’å…ƒã®çŠ¶æ…‹ã«å¾©å…ƒã—ã¾ã—ãŸ")
        except Exception as e:
            print(f"âŒ ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
    
    try:
        # 1. æŒ¿å…¥ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã®ä¿æŒ
        print(f"ğŸ“¦ æŒ¿å…¥ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒä¸­...")
        items_to_insert = copy.deepcopy(items_to_move)
        print(f"   - ä¿æŒã—ãŸãƒ‡ãƒ¼ã‚¿æ•°: {len(items_to_insert)}å€‹")
        print(f"   - ä¿æŒã—ãŸãƒ‡ãƒ¼ã‚¿: {list(items_to_insert.keys())}")
        
        # 2. æŒ¿å…¥å…ˆã«ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ 
        print(f"ğŸ“¥ æŒ¿å…¥å…ˆã«ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ä¸­...")
        print(f"   - æŒ¿å…¥å…ˆID: {destination_id}")
        print(f"   - æŒ¿å…¥å…ˆã®ç¾åœ¨ã®çŠ¶æ…‹: {destination_node.get('is_leaf')}")
        
        # æ—¢å­˜ã®destination_nodeã‚’ä½¿ç”¨ï¼ˆå†å–å¾—ã¯ä¸è¦ï¼‰
        if "data" not in destination_node:
            destination_node["data"] = {}
            print(f"   - dataãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
        
        print(f"   - æŒ¿å…¥å‰ã®è¦ç´ æ•°: {len(destination_node['data'])}")
        print(f"   - æŒ¿å…¥å‰ã®è¦ç´ : {list(destination_node['data'].keys())}")
        
        # ç§»å‹•å…ˆã«è¦ç´ ã‚’è¿½åŠ 
        for key, value in items_to_insert.items():
            destination_node["data"][key] = value
            print(f"   âœ… è¿½åŠ : {key} â†’ {destination_id}")
        
        print(f"   - æŒ¿å…¥å¾Œã®è¦ç´ æ•°: {len(destination_node['data'])}")
        print(f"   - æŒ¿å…¥å¾Œã®è¦ç´ : {list(destination_node['data'].keys())}")
        print(f"âœ… æŒ¿å…¥å…ˆã¸ã®è¿½åŠ å®Œäº†: {len(items_to_insert)}å€‹ã®è¦ç´ ã‚’è¿½åŠ ")
        
        # 3. æŒ¿å…¥å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
        print(f"ğŸ—‘ï¸  æŒ¿å…¥å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ä¸­...")
        
        def remove_items_from_source(node_dict, target_ids, item_type):
            """ç§»å‹•å…ƒã‹ã‚‰è¦ç´ ã‚’å‰Šé™¤"""
            removed_count = 0
            for key, value in list(node_dict.items()):
                if key in target_ids:
                    if item_type == "folders" and isinstance(value, dict):
                        del node_dict[key]
                        removed_count += 1
                        print(f"   âœ… å‰Šé™¤: {key} (ãƒ•ã‚©ãƒ«ãƒ€)")
                    elif item_type == "images" and isinstance(value, str):
                        del node_dict[key]
                        removed_count += 1
                        print(f"   âœ… å‰Šé™¤: {key} (ç”»åƒ)")
                
                # å†å¸°çš„ã«æ¤œç´¢ãƒ»å‰Šé™¤
                if isinstance(value, dict) and "data" in value:
                    sub_removed = remove_items_from_source(value["data"], target_ids, item_type)
                    removed_count += sub_removed
            
            return removed_count
        
        removed_count = remove_items_from_source(result_structure, sources, source_type)
        print(f"âœ… æŒ¿å…¥å…ƒã‹ã‚‰ã®å‰Šé™¤å®Œäº†: {removed_count}å€‹ã®è¦ç´ ã‚’å‰Šé™¤")
        
        # å‰Šé™¤å¾Œã®æŒ¿å…¥å…ˆã®çŠ¶æ…‹ã‚’ç¢ºèª
        print(f"ğŸ” å‰Šé™¤å¾Œã®æŒ¿å…¥å…ˆã®çŠ¶æ…‹ç¢ºèª...")
        print(f"   - æŒ¿å…¥å…ˆã®è¦ç´ æ•°: {len(destination_node['data'])}")
        print(f"   - æŒ¿å…¥å…ˆã®è¦ç´ : {list(destination_node['data'].keys())}")
        
        json.dump(result_structure, open("c.json", "w"), indent=4)
        # 4. MongoDBã«ä¿å­˜
        print(f"ğŸ’¾ MongoDBã«ä¿å­˜ä¸­...")
        result_manager._mongo_module.update_document(
            collection_name='clustering_results',
            query={"mongo_result_id": mongo_result_id},
            update={"result": result_structure}
        )
        print(f"âœ… MongoDBä¿å­˜å®Œäº†")
        
        # ä¿å­˜å¾Œã®ç¢ºèª
        print(f"ğŸ” ä¿å­˜å¾Œã®ç¢ºèªä¸­...")
        saved_result = result_manager._mongo_module.find_one_document(
            collection_name='clustering_results',
            query={"mongo_result_id": mongo_result_id}
        )
        if not saved_result:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: ä¿å­˜å¾Œã®ç¢ºèªã§ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            raise Exception("Data not found after save")
        
        saved_structure = saved_result.get("result", {})
        print(f"   - ä¿å­˜ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®è¦ç´ æ•°: {len(saved_structure)}")
        print(f"   - ä¿å­˜ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®è¦ç´ : {list(saved_structure.keys())}")
        
        # 5. ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®è¿”å´
        print(f"âœ… ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")
        print(f"   - ç§»å‹•å¯¾è±¡æ•°: {len(items_to_insert)}å€‹")
        print(f"   - ç§»å‹•ã‚¿ã‚¤ãƒ—: {source_type}")
        print(f"   - ç§»å‹•å…ˆ: {destination_folder}")
        print(f"   - ç§»å‹•å¯¾è±¡ID: {list(items_to_insert.keys())}")
        print(f"   - å‰Šé™¤æ•°: {removed_count}å€‹")
        
        return JSONResponse(
            status_code=status.HTTP_200_OK,
            content={
                "message": f"Successfully moved {len(items_to_insert)} {source_type} to '{destination_folder}'",
                "data": {
                    "moved_items": list(items_to_insert.keys()),
                    "destination_folder": destination_folder,
                    "source_type": source_type,
                    "moved_count": len(items_to_insert),
                    "removed_count": removed_count,
                    "operation_completed": True
                }
            }
        )
        
    except Exception as e:
        print(f"âŒ å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        print(f"ğŸ”„ ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™...")
        rollback_data()
        
        return JSONResponse(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            content={
                "message": f"Operation failed and rolled back: {str(e)}",
                "data": {
                    "error": str(e),
                    "rolled_back": True,
                    "original_state_restored": True
                }
            }
        )